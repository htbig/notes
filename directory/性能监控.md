# 性能监控
* 使用telegraf influxdb kapacitor chronograf 监控性能：
```
1：安装这四个在同一台host，不同的也可以;
2:创建influxdb的conf文件，在host的/etc/influxdb创建influxdb.conf文件，跑docker run -d influxdb然后将/etc/influxdb下的influxdb.conf拷贝到host机器;
docker run -d --name influxdb --restart=always -v /etc/influxdb/:/etc/influxdb -v /var/lib/influxdb/:/var/lib/influxdb/ -p 8086:8086 influxdb
3:将docker里的conf文件拷贝出来，在宿主机上创建，执行docker run -v /etc/telegraf/:/etc/telegraf/ di│telegraf
8086端口influxdb占用
8092/udp, 8125/udp, 8094/tcp telegraf占用
遇到问题：influxdb会根据kapacitor的hostname:port来发送从telegraf发过来的包，但是我的kapacitor是跑在docker里面，hostname是随意的一个值，所以解决办法是docker run时指定容器hostname为宿主机ip，这样influxdb从搜集器telegraf搜集来的数据发送给kapacitor:
kapacitor.conf内容：
httppost = []
hostname = "work"	
data_dir = "/var/lib/kapacitor"
skip-config-overrides = false
default-retention-policy = ""

[http]
  bind-address = ":9092"
  auth-enabled = false
  log-enabled = true
  write-tracing = false
  pprof-enabled = false
  https-enabled = false
  https-certificate = "/etc/ssl/kapacitor.pem"
  shutdown-timeout = "10s"
  shared-secret = ""

[replay]
  dir = "/var/lib/kapacitor/replay"

[storage]
  boltdb = "/var/lib/kapacitor/kapacitor.db"

[task]
  dir = "/root/.kapacitor/tasks"
  snapshot-interval = "1m0s"

[[influxdb]]
  enabled = true
  name = "default"
  default = false
  urls = ["http://10.4.32.153:8086"]
  username = ""
  password = ""
  ssl-ca = ""
  ssl-cert = ""
  ssl-key = ""
  insecure-skip-verify = false
  timeout = "0s"
  disable-subscriptions = false
  subscription-protocol = "http"
  kapacitor-hostname = ""
  http-port = 0
  udp-bind = ""
  udp-buffer = 1000
  udp-read-buffer = 0
  startup-timeout = "5m0s"
  subscriptions-sync-interval = "1m0s"
  [influxdb.excluded-subscriptions]
    _kapacitor = ["autogen"]

[logging]
  file = "STDERR"
  level = "INFO"

[config-override]
  enabled = true

[collectd]
  enabled = false
  bind-address = ":25826"
  database = "collectd"
  retention-policy = ""
  batch-size = 5000
  batch-pending = 10
  batch-timeout = "10s"
  read-buffer = 0
  typesdb = "/usr/share/collectd/types.db"

[opentsdb]
  enabled = false
  bind-address = ":4242"
  database = "opentsdb"
  retention-policy = ""
  consistency-level = "one"
  tls-enabled = false
  certificate = "/etc/ssl/influxdb.pem"
  batch-size = 1000
  batch-pending = 5
  batch-timeout = "1s"
  log-point-errors = true

[alerta]
  enabled = false
  url = ""
  insecure-skip-verify = false
  token = ""
  token-prefix = ""
  environment = ""
  origin = ""

[hipchat]
  enabled = false
  url = ""
  token = ""
  room = ""
  global = false
  state-changes-only = false

[opsgenie]
  enabled = false
  api-key = ""
  url = "https://api.opsgenie.com/v1/json/alert"
  recovery_url = "https://api.opsgenie.com/v1/json/alert/note"
  global = false

[pagerduty]
  enabled = false
  url = "https://events.pagerduty.com/generic/2010-04-15/create_event.json"
  service-key = ""
  global = false

[pushover]
  enabled = false
  token = ""
  user-key = ""
  url = "https://api.pushover.net/1/messages.json"

[smtp]
  enabled = false
  host = "localhost"
  port = 25
  username = ""
  password = ""
  no-verify = false
  global = false
  state-changes-only = false
  from = ""
  idle-timeout = "30s"

[snmptrap]
  enabled = false
  addr = "localhost:162"
  community = "kapacitor"
  retries = 1

[sensu]
  enabled = false
  addr = ""
  source = "Kapacitor"

[slack]
  enabled = false
  url = ""
  channel = ""
  username = "kapacitor"
  icon-emoji = ""
  global = false
  state-changes-only = false
  ssl-ca = ""
  ssl-cert = ""
  ssl-key = ""
  insecure-skip-verify = false

[talk]
  enabled = false
  url = ""
  author_name = ""

[telegram]
  enabled = false
  url = "https://api.telegram.org/bot"
  token = ""
  chat-id = ""
  parse-mode = ""
  disable-web-page-preview = false
  disable-notification = false
  global = false
  state-changes-only = false

[victorops]
  enabled = false
  api-key = ""
  routing-key = ""
  url = "https://alert.victorops.com/integrations/generic/20131114/alert"
  global = false

[reporting]
  enabled = true
  url = "https://usage.influxdata.com"

[stats]
  enabled = true
  stats-interval = "10s"
  database = "_kapacitor"
  retention-policy = "autogen"
  timing-sample-rate = 0.1
  timing-movavg-size = 1000

[udf]

[deadman]
  interval = "10s"
  threshold = 0.0
  id = "{{ .Group }}:NODE_NAME for task '{{ .TaskName }}'"
  message = "{{ .ID }} is {{ if eq .Level \"OK\" }}alive{{ else }}dead{{ end }}: {{ index .Fields \"emitted\" | printf \"%0.3f\" }} points/INTERVAL."
  global = false

docker run -v /etc/kapacitor/:/etc/kapacitor/ -v /root:/root --hostname 172.21.78.51 -p 9092:9092 kapacitor
4：编写task出发trigger：
编写.tick文件
执行kapacitor 去注册tasks
docker exec c3b9ca9f7c27 kapacitor define cpu_alert     -type stream     -tick /root/cpu_alert.tick     -dbrp kapacitor_example.autogen
docker exec c3b9ca9f7c27 kapacitor record stream -task cpu_alert -duration 20s
docker exec c3b9ca9f7c27 kapacitor list recordings eb56d160-8d9f-4528-af80-2294a1a9f026
 docker exec 7c61c580114f kapacitor replay -recording eb56d160-8d9f-4528-af80-2294a1a9f026 -task cpu_alert
docker cp 7c61c580114f:/tmp/alerts.log ./
可以看到alerts.log里一堆log
修改了.tick文件就需要重新执行：
# edit threshold in cpu_alert.tick and redefine the task.
kapacitor define cpu_alert -tick cpu_alert.tick
kapacitor replay -recording $rid -task cpu_alert
都ok了之后，我们就来enable tasks
kapacitor enable cpu_alert

kapacitor show cpu_alert
ddd
启动chronograf:
docker run -d --name chronograf -v /var/lib/chronograf:/var/lib/chronograf --restart=always -p 8888:8888 -i chronograf

docker run -d --restart=always --name kapacitor -v /etc/kapacitor/:/etc/kapacitor/ -v /var/lib/kapacitor:/var/lib/kapacitor --hostname 192.168.66.102 -p 9092:9092 kapacitor
docker run -p 8887:8888 chronograf
安装pacman -S docker-compose
编写docker-compose.yml文件：
version: '2'
services:
   telegraf:
      image: "telegraf"
      ports:
        - "8092:8092/udp"
        - "8125:8125/udp"
        - "8094:8094"
      volumes:
        - /home/ht/monitor-compose/root/etc/telegraf:/etc/telegraf
   influxdb:
      image: "influxdb"
      ports:
        - "8086:8086"
      volumes:
        - /home/ht/monitor-compose/root/etc/influxdb:/etc/influxdb
        - /home/ht/monitor-compose/root/var/lib/influxdb:/var/lib/influxdb
   kapacitor:
      image: "kapacitor"
      ports:
        - "9092:9092"
      volumes:
        - /home/ht/monitor-compose/root/etc/kapacitor:/etc/kapacitor
        - /home/ht/monitor-compose/root:/root
        - /home/ht/monitor-compose/root/var/lib/kapacitor:/var/lib/kapacitor
      environment:
        HOSTNAME: "172.21.78.50"
   chronograf:
      image: "chronograf"
      ports:
        - "8888:8888"
配置chronograf：
打开部署了服务的机器：
http://172.21.78.50
部署不同机器上telegraf, influxdb, kapacitor, chronograf:
1:分别pacman -U telegraf-1.0.0-1-x86_64.pkg.tar.xz在不同虚拟机上。
2：修改/etc/telegraf/telegraf.conf文件：
总结：telegraf将设备侧数据收集过来发送到influxdb上，influxdb数据可以在chronograf上渲染，Query data from InfluxDB on a schedule, and receive data via the line protocol and any other method InfluxDB supports.Store transformed data back in InfluxDB.
Chronograf offers a UI for Kapacitor, InfluxData’s data processing framework for creating alerts, running ETL jobs, and detecting anomalies in your data
influxdb是非常优秀的时序数据库，但是只有单机版本是免费，
我们云端的数据保存在postgresql里，但是设备的实时数据保存在influxdb实时数据库上。
telegraf将设备数据
[[inputs.exec]]
commands = ["/bin/iot -g devtype SL_SC_BE"]
timeout = "5s"
data_format = "json"
name_suffix = "iot_info"

关于内存泄露问题，结论是goroutine未退出导致。
2分钟泄露0.88M, 0.79M
go program memory leaks check:
利用go自带的net/http/pprof/
1：reflect的 MapIndex内存泄露
2：json.Unmarshal内存问题
3：json.Marshal内存泄露
4：ioutil.WriteFile内存泄露
5：json.NewEncoder(ctx.Writer).Encode(data)内存泄露
6：CamInfo map[string]CameraInfo赋值内存泄露
7：RunScript不停执行execCommand("/bin/sh", "-c", cmd).CombinedOutput()内存泄露
8：PatchSnap内存泄露
9：reflect.DeepEqual(v1_val.MapIndex(key).Interface(), v2_val.MapIndex(key).Interface())内存泄露
10：fmt.Sprintf("Camera%d", camera[key_camera].DevId)内存泄露
11：SnapCameraImage里的ioutil.ReadAll内存泄露
12：SnapCameraLoop内存泄露
13：output, err := ioutil.ReadFile(filename)内存泄露
14：snapServer.ReadFromUDP(buffer)内存泄露
15：resolution = []string{mainimsize, subimsize}内存泄露
```

